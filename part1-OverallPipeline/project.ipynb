{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aytekin Erdogan 2532703 Lane Detection Pipeline\n",
    "\n",
    "### All necessary explanation is commented inside the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First calibrate the camera and remove distortion effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_calibration(img_path,cal_img_list):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = cal_img_list\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "#         print(img_path + fname)\n",
    "        img = cv2.imread(img_path + fname)\n",
    "        #plt.imshow(img)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        if ret == True:\n",
    "            # add object points, image points\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objectPoints=objpoints,\n",
    "                                   imagePoints=imgpoints,\n",
    "                                   imageSize=gray.shape[::-1],\n",
    "                                   cameraMatrix=None,\n",
    "                                   distCoeffs=None)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwarp(img):\n",
    "    src = np.float32([[200,img.shape[0]], [1130,img.shape[0]],[590,450],[685,450]])\n",
    "    # For destination points, arbitrarily choose some points that is nice fit for displaying our warped result \n",
    "    dst = np.float32([[300,img.shape[0]], [1070, img.shape[0]], [300,0], [1070, 0]])\n",
    "    \n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size)\n",
    "\n",
    "    # Return the output image and corresponding matrix\n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_combined(img):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    # Convert to hls color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    s_channel = hls[:,:,2]\n",
    "    ret,s_binary = cv2.threshold(s_channel.astype('uint8'), 88, 190, cv2.THRESH_BINARY)\n",
    "    \n",
    "    sobel_kernel = 9\n",
    "    # Pass images through sobel filter for both grayscale and s channel\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "\n",
    "    # Scale to 8-bit (0 - 255) and type = np.uint8\n",
    "    scaled_x = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    scaled_y = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    \n",
    "    # Create a binary mask\n",
    "    # Combine sobel outputs of S channel and grayscale channelwise\n",
    "    binary_outputx = np.zeros_like(scaled_x)\n",
    "    binary_outputx[((scaled_x >= 25)&(scaled_x <= 50))] = 1\n",
    "    \n",
    "    binary_outputy = np.zeros_like(scaled_y)\n",
    "    binary_outputy[((scaled_y >= 50)&(scaled_y <= 150))] = 1\n",
    "    \n",
    "    # Combine binary images for x and y channels\n",
    "    # Sobel abs thresholded img\n",
    "    comb_xy = cv2.bitwise_or(np.uint8(binary_outputy),np.uint8(binary_outputx))\n",
    "    \n",
    "    # Calculate the magnitude of sobel images seperately for grayscale\n",
    "    abs_xy = np.sqrt(abs_sobelx**2 + abs_sobely**2)\n",
    "    \n",
    "    scaled = np.uint8(255*abs_xy/np.max(abs_xy))\n",
    "\n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    binary_output_mag = np.zeros_like(abs_xy)\n",
    "    binary_output_mag[(scaled <= 250) & (scaled >= 50)] = 1\n",
    "    \n",
    "    # Calculate the direction of the gradient \n",
    "    g_dir = np.arctan2(abs_sobelx, abs_sobely)\n",
    "    \n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output_dir = np.zeros_like(g_dir)\n",
    "    binary_output_dir[((g_dir >= 0.7) & (g_dir <= 1.3))] = 1\n",
    "    \n",
    "    kernel_1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n",
    "    kernel_2 = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "    kernel_3 = cv2.getStructuringElement(cv2.MORPH_CROSS,(7,7))\n",
    "    \n",
    "    combined = np.zeros_like(binary_output_dir)\n",
    "    combined[(comb_xy == 1) | ((binary_output_mag == 1) & (binary_output_dir == 1)) | (s_binary >=150)] = 1\n",
    "    \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    combined = cv2.morphologyEx(combined.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_combined_new(img):\n",
    "    hsv_min = np.array([0, 70, 70])\n",
    "    hsv_max = np.array([50, 255, 255])\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    yellow = cv2.inRange(hsv,hsv_min,hsv_max )\n",
    "    yellow = np.uint8(255*yellow/np.max(yellow))\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    _, white = cv2.threshold(hist, thresh=250, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    white = np.uint8(255*white/np.max(white))\n",
    "    \n",
    "    combined = np.zeros_like(gray)\n",
    "    combined[(white >= 250) | (yellow >= 250)] = 1\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List test images\n",
    "test_images = os.listdir(\"inputs\")\n",
    "#print(test_images)\n",
    "\n",
    "#Set output images directory\n",
    "output_dir = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_combined_old(img):\n",
    "    hsv_min = np.array([0, 70, 70])\n",
    "    hsv_max = np.array([50, 255, 255])\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#     print(\"x\")\n",
    "#     print(hsv.shape)\n",
    "    min_th_ok = np.all(hsv > hsv_min)\n",
    "#     print(\"x\")\n",
    "    max_th_ok = np.all(hsv < hsv_max, axis=2)\n",
    "#     print(\"x\")\n",
    "    yellow = np.logical_and(min_th_ok, max_th_ok)\n",
    "#     print(\"x\")\n",
    "    height, width = img.shape[:2]\n",
    "    binary = np.zeros(shape=(height, width), dtype=np.uint8)\n",
    "#     print(\"x\")\n",
    "    binary = np.logical_or(binary, yellow)\n",
    "#     print(\"x\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#     print(\"x\")\n",
    "    hist = cv2.equalizeHist(gray)\n",
    "    _, white = cv2.threshold(hist, thresh=250, maxval=255, type=cv2.THRESH_BINARY)\n",
    "#     print(\"x\")\n",
    "    binary = np.logical_or(binary, white)\n",
    "#     print(\"x\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     print(\"x\")\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=9)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=9)\n",
    "#     print(\"x\")\n",
    "    sobel_mag = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "    sobel_mag = np.uint8(sobel_mag / np.max(sobel_mag) * 255)\n",
    "#     print(\"x\")\n",
    "    _, sobel_mag = cv2.threshold(sobel_mag, 50, 1, cv2.THRESH_BINARY)\n",
    "#     print(\"x\")\n",
    "    binary = np.logical_or(binary, sobel_mag.astype(bool))\n",
    "#     print(\"x\")\n",
    "    return binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255, sthresh_min=0, sthresh_max=255):\n",
    "    #Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "        abs_ssobel = np.absolute(cv2.Sobel(s_channel, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "        abs_ssobel = np.absolute(cv2.Sobel(s_channel, cv2.CV_64F, 0, 1))\n",
    "    \n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    s_scaled = np.uint8(255*abs_ssobel/np.max(abs_ssobel))\n",
    "    \n",
    "    # Create a mask of 1's where the scaled gradient magnitude\n",
    "    binary_output = np.zeros_like(scaled)\n",
    "    binary_output[((scaled >= thresh_min)&(scaled <= thresh_max))] = 1\n",
    "    sbinary_output = np.zeros_like(s_scaled)\n",
    "    sbinary_output = ((s_scaled >= sthresh_min)&(s_scaled <= sthresh_max))\n",
    "    img_bwo = cv2.bitwise_or(np.uint8(sbinary_output),np.uint8(binary_output))\n",
    "    \n",
    "    return img_bwo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    xs = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    ys = cv2.Sobel(s_channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Calculate the magnitude \n",
    "    abs_xy = np.sqrt(x**2 + y**2)\n",
    "    abs_xys = np.sqrt(xs**2 + ys**2)\n",
    "    \n",
    "    # Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled = np.uint8(255*abs_xy/np.max(abs_xy))\n",
    "    s_scaled = np.uint8(255*abs_xys/np.max(abs_xys))\n",
    "    \n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(abs_xy)\n",
    "    binary_output[(scaled <= mag_thresh[1]) & (scaled >= mag_thresh[0])|(s_scaled <= mag_thresh[1]) & (s_scaled >= mag_thresh[0])] = 1\n",
    "    \n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Calculate the magnitude \n",
    "    abs_x = np.absolute(x)\n",
    "    abs_y = np.absolute(y)\n",
    "    \n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    g_dir = np.arctan2(abs_y, abs_x)\n",
    "    \n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(g_dir)\n",
    "    binary_output[(g_dir >= thresh[0]) & (g_dir <= thresh[1])] = 1\n",
    "    \n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take the histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram to find the starting point for the left and right lines\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # H-parameters\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = int(binary_warped.shape[0]//nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        \n",
    "        # Finding the four below boundaries of the window\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current -margin\n",
    "        win_xright_high = rightx_current +margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find lane pixels\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    # Visualize colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "   \n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img, ploty, left_fitx, right_fitx, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvature_radius (leftx, rightx, img_shape, xm_per_pix=3.7/800, ym_per_pix = 25/720):\n",
    "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])\n",
    "    \n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 25/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/800 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    y_eval = np.max(ploty)\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # radius of curvature is in meters\n",
    "    return (left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_output(undist, warped, Minv, ploty, left_fitx, right_fitx, left_fit, right_fit):\n",
    "    # Calculate radius of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700\n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curvature =  ((1 + (2*left_fit_cr[0] *y_eval*ym_per_pix + left_fit_cr[1])**2) **1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curvature = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "#     print((right_curvature+left_curvature)/2)\n",
    "    \n",
    "    # Calculate vehicle center\n",
    "    #left_lane and right lane bottom in pixels\n",
    "    left_lane_bottom = (left_fit[0]*y_eval)**2 + left_fit[0]*y_eval + left_fit[2]\n",
    "    right_lane_bottom = (right_fit[0]*y_eval)**2 + right_fit[0]*y_eval + right_fit[2]\n",
    "    avg_curvature = (right_curvature + left_curvature)/2\n",
    "#     print(avg_curvature)\n",
    "    \n",
    "    # Lane center as mid of left and right lane bottom                        \n",
    "    lane_center = (left_lane_bottom + right_lane_bottom)/2.\n",
    "    center_image = 640\n",
    "    center = (lane_center - center_image)*xm_per_pix #Convert to meters\n",
    "#     print(center)\n",
    "    \n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    cmon = np.flipud(np.transpose(np.vstack([right_fitx, ploty]))).copy()\n",
    "    pts_right = np.array([cmon])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "#     print(\"points: \")\n",
    "#     print(pts)\n",
    "#     print(\"pts_vals: \")\n",
    "#     print(pts.shape[1])\n",
    "#     print(pts[0][pts.shape[1]-1][0])\n",
    "#     print(pts[0,0])\n",
    "#     print(\"pts_len: \")\n",
    "#     print(pts[0,-1])\n",
    "#     print(pts[0,300])\n",
    "#     print(\"check\")\n",
    "    Minv = np.linalg.inv(Minv)\n",
    "    pts_prev = pts\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    curv_info = \"Curvuture: \" + str(avg_curvature) +\"m\"\n",
    "    if center < 0:\n",
    "        center_info = \"Vehicle is \" + str(np.abs(center)) + \"m left of center\"\n",
    "    else:\n",
    "        center_info = \"Vehicle is \" + str(np.abs(center)) + \"m right of center\"\n",
    "    cv2.putText(result,center_info,(30,100), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    cv2.putText(result,curv_info,(30,30), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    plt.imshow(result)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change current working directory\n",
    "os.chdir(\"/home/aerdog14/REPO/courses/metu/mmi702-project/part1- pipeline\")\n",
    "# List camera calibration images\n",
    "calibration_imgs = os.listdir(\"camera_cal/\")\n",
    "\n",
    "# Get camera and distortion matrices\n",
    "mtx, dst = camera_calibration(\"camera_cal/\", calibration_imgs)\n",
    "\n",
    "# Test with chessboard if undistortion works well or not \n",
    "test_img = cv2.imread(\"camera_cal/calibration1.jpg\")\n",
    "im= undistort(test_img,mtx,dst)\n",
    "# plt.imshow(im)\n",
    "\n",
    "#Set output images directory\n",
    "output_dir = \"outputs/\"\n",
    "cv2.imwrite(output_dir + \"original_calibration1.jpg\" , test_img)\n",
    "cv2.imwrite(output_dir + \"undis_calibration1.jpg\", im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List test images\n",
    "# test_images = os.listdir(\"rev_inputs\")\n",
    "test_images = os.listdir(\"test_images\")\n",
    "# print(test_images)\n",
    "\n",
    "#Set output images directory\n",
    "# output_dir = \"rev_outputs/\"\n",
    "output_dir = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_im in test_images:\n",
    "    if test_im.endswith(\".jpeg\") or test_im.endswith(\".jpg\"):\n",
    "        img = image = mpimg.imread(\"test_images/\" + test_im)\n",
    "        undist= undistort(img,mtx,dst)\n",
    "        cv2.imwrite(output_dir + \"undist_\" +test_im, undist)\n",
    "#         plt.imshow(undist)\n",
    "        \n",
    "        combined = sobel_combined(undist)\n",
    "        combined = combined *255\n",
    "#         plt.imshow(combined, cmap=\"gray\")\n",
    "        cv2.imwrite(output_dir + \"binary_combo_\" +test_im, combined)\n",
    "\n",
    "        im, M = unwarp(combined)\n",
    "        cv2.imwrite(output_dir + \"warped_\" +test_im, im)\n",
    "#         plt.imshow(im)\n",
    "\n",
    "        out_img, ploty, left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(im)\n",
    "        cv2.imwrite(output_dir + \"fit_\" +test_im, out_img)\n",
    "#         plt.imshow(out_img)\n",
    "\n",
    "\n",
    "        result = show_output(undist, im, M, ploty, left_fitx, right_fitx, left_fit, right_fit)\n",
    "        cv2.imwrite(output_dir + \"output_\" + test_im, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f572f600250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp_zero = np.zeros_like(im).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "cmon = np.flipud(np.transpose(np.vstack([right_fitx, ploty]))).copy()\n",
    "pts_right = np.array([cmon])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "M = np.linalg.inv(M)\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, M, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_pts = []\n",
    "latent1_pts = []\n",
    "latent2_pts = []\n",
    "latent3_pts = []\n",
    "isFirstFrame = True;\n",
    "isSecondFrame = True;\n",
    "isThirdFrame = True;\n",
    "\n",
    "def show_output_new(undist, warped, Minv, ploty, left_fitx, right_fitx, left_fit, right_fit):\n",
    "    global isFirstFrame,isSecondFrame, isThirdFrame\n",
    "    global prev_pts, latent2_pts, latent1_pts, latent3_pts\n",
    "    # Calculate radius of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700\n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curvature =  ((1 + (2*left_fit_cr[0] *y_eval*ym_per_pix + left_fit_cr[1])**2) **1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curvature = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "#     print((right_curvature+left_curvature)/2)\n",
    "    \n",
    "    # Calculate vehicle center, left_lane and right lane bottom in pixels\n",
    "    left_lane_bottom = (left_fit[0]*y_eval)**2 + left_fit[0]*y_eval + left_fit[2]\n",
    "    right_lane_bottom = (right_fit[0]*y_eval)**2 + right_fit[0]*y_eval + right_fit[2]\n",
    "    avg_curvature = (right_curvature + left_curvature)/2\n",
    "#     print(avg_curvature)\n",
    "    \n",
    "    # Lane center as mid of left and right lane bottom                        \n",
    "    lane_center = (left_lane_bottom + right_lane_bottom)/2.\n",
    "    center_image = 640\n",
    "    center = (lane_center - center_image)*xm_per_pix #Convert to meters\n",
    "#     print(center)\n",
    "    \n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    cmon = np.flipud(np.transpose(np.vstack([right_fitx, ploty]))).copy()\n",
    "    pts_right = np.array([cmon])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    if isThirdFrame and not(isSecondFrame) and not(isFirstFrame):\n",
    "        latent3_pts = latent2_pts\n",
    "        latent2_pts = latent1_pts\n",
    "        latent1_pts = pts\n",
    "        prev_pts = pts\n",
    "        isThirdFrame = False\n",
    "    elif isThirdFrame and isSecondFrame and not(isFirstFrame):\n",
    "        latent2_pts = latent1_pts\n",
    "        latent1_pts = pts\n",
    "        prev_pts = pts\n",
    "        isSecondFrame = False\n",
    "    elif isFirstFrame:\n",
    "        isFirstFrame = False\n",
    "        prev_pts = pts\n",
    "        latent1_pts = pts\n",
    "    else:\n",
    "#         print( \"previous\")\n",
    "#         print(prev_pts[0][prev_pts.shape[1]-1][0])\n",
    "#         print(pts[0][pts.shape[1]-1][0])\n",
    "        if abs(prev_pts[0][prev_pts.shape[1]-1][0]-pts[0][pts.shape[1]-1][0]) >=25 or abs(prev_pts[0][0][0]-pts[0][0][0]) >=25:\n",
    "            dummy = pts\n",
    "            pts = prev_pts\n",
    "            prev_pts = dummy\n",
    "#             print( \"SKIPPED!\")\n",
    "        else:\n",
    "            prev_pts = pts\n",
    "        dummy1 = latent1_pts\n",
    "        dummy2 = latent2_pts\n",
    "        newpts = (pts + latent3_pts + latent2_pts + latent1_pts) /4\n",
    "        latent1_pts = pts\n",
    "        latent2_pts = dummy1\n",
    "        latent3_pts = dummy2\n",
    "        pts = newpts\n",
    "        \n",
    "        \n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, int([pts]), (0,255, 0))\n",
    "#     print(\"points: \")\n",
    "#     print(pts)\n",
    "#     print(\"pts_vals: \")\n",
    "#     print(pts[0,0])\n",
    "#     print(\"pts_len: \")\n",
    "#     print(pts[0,-1])\n",
    "#     print(pts[0,300])\n",
    "#     print(\"check\")\n",
    "    Minv = np.linalg.inv(Minv)\n",
    "    pts_prev = pts\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    curv_info = \"Avg curvature of the road is: \" + str(float(\"{:.2f}\".format(avg_curvature))) +\"m\"\n",
    "    center = float(\"{:.2f}\".format(center))\n",
    "    if center < 0:\n",
    "        center_info = \"Vehicle is \" + str(np.abs(center)) + \"m left of center\"\n",
    "    else:\n",
    "        center_info = \"Vehicle is \" + str(np.abs(center)) + \"m right of center\"\n",
    "    cv2.putText(result,center_info,(30,100), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    cv2.putText(result,curv_info,(30,30), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "#     plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    undist= undistort(img,mtx,dst)\n",
    "    \n",
    "    combined = sobel_combined(undist)\n",
    "    combined = combined *255\n",
    "    \n",
    "    im, M = unwarp(combined)\n",
    "    \n",
    "    out_img, ploty, left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(im)    \n",
    "    \n",
    "    result = show_output_new(undist, im, M, ploty, left_fitx, right_fitx, left_fit, right_fit)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24016/1454795784.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import imageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# imageio.plugins.ffmpeg.download()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0misFirstFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "# import imageio\n",
    "# imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "isFirstFrame = True;\n",
    "white_output = 'video1_output.mp4'\n",
    "clip1 = VideoFileClip(\"video1.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "print(\"Start of writing!\")\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "print(\"Writing is completed!\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "white_output = 'video1_output.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "isFirstFrame = True;\n",
    "white_output = 'video2_output.mp4'\n",
    "clip1 = VideoFileClip(\"video2.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "print(\"Start of writing!\")\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "print(\"Writing is completed!\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "white_output = 'video2_output.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "isFirstFrame = True;\n",
    "white_output = 'video3_output.mp4'\n",
    "clip1 = VideoFileClip(\"video3.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "print(\"Start of writing!\")\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "print(\"Writing is completed!\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "white_output = 'video3_output.mp4'\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
